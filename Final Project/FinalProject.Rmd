---
title: "GGIS 224 Final Project"
output: html_document
author: Jonathan Bernard Widjajakusuma
date: "2024-04-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

```{r libraries, message=FALSE}
library(tidyr)
library(dplyr)
library(sf)
library(spData)
library(tidyverse)
library(terra)
library(rgeoda)
library(tmap)
library(raster)
library(tidycensus)
library(httr)
library(jsonlite)
library(ggplot2)
library(spdep)
```

## Data Wrangling for Crime Dataset
``` {r mapping}
# Loading Dataset
crime_data <- read.csv("/Users/jonathanbernard/Desktop/UIUC/Spring 2024/GGIS 224/GGIS224/Final Project/Datasets/Crimes_-_Map.csv")

# Remove unecessary columns
crime_data_filtered <- crime_data[, c("BLOCK", "X.COORDINATE", "Y.COORDINATE", "LATITUDE", "LONGITUDE", "LOCATION")]

crime_count <- aggregate(BLOCK ~ LOCATION, data = crime_data_filtered, FUN = length)

colnames(crime_count) <- c("LOCATION", "CRIME_COUNT")

crime_data_result <- merge(crime_data_filtered[, !names(crime_data_filtered) %in% "BLOCK"], crime_count, by = "LOCATION", all.x = TRUE)

crime_data_result <- crime_data_result[!duplicated(crime_data_result$LOCATION), ]

# Load the census tract shapefile
census_tracts <- st_read("/Users/jonathanbernard/Desktop/UIUC/Spring 2024/GGIS 224/GGIS224/Final Project/Datasets/Boundaries - Census Tracts - 2010.geojson")

# Remove rows with missing coordinates
crime_data_result <- crime_data_result %>%
  filter(!is.na(LONGITUDE) & !is.na(LATITUDE))

# Convert the crime data to an sf object
crime_data_sf <- st_as_sf(crime_data_result, coords = c("LONGITUDE", "LATITUDE"), crs = 4326)

# Spatial join the crime data with the census tracts
crime_data_tract <- st_join(census_tracts, crime_data_sf)

# Aggregate the crime count by census tract
crime_data_tract_agg <- crime_data_tract %>%
  group_by(geoid10) %>%
  summarize(CRIME_COUNT = sum(CRIME_COUNT, na.rm = TRUE))

# Convert the aggregated crime data to an sf object
crime_data_tract_agg_sf <- st_as_sf(crime_data_tract_agg, coords = c("LONGITUDE", "LATITUDE"), crs = 4326)

# Merge the census tract shapefile with the aggregated crime data
census_tracts_crime <- st_join(census_tracts, crime_data_tract_agg_sf, join = st_intersects, left = TRUE)

# Define the breaks for the crime count intervals
breaks <- c(0, 50, 100, 200, 300, 400, 500, 1000, 2000, 3000, 4000, 5000, Inf)

# Define the labels for the crime count intervals
labels <- c("0-50", "50-100", "100-200", "200-300", "300-400", "400-500",
            "500-1000", "1000-2000", "2000-3000", "3000-4000", "4000-5000", "5000+")

# Create an interactive heatmap using tmap
tmap_mode("view")
tm_shape(census_tracts_crime) +
  tm_polygons("CRIME_COUNT", title = "Crime Count", breaks = breaks, labels = labels,
              palette = "YlOrRd", alpha = 0.7) +
  tm_view(set.zoom.limits = c(10, 14)) +
  tm_scale_bar() +
  tm_minimap() +
  tm_credits("Data Source: Chicago Crime Data", position = c("LEFT", "BOTTOM"))
```


## Data Wrangling for Economic Dataset
```{r cleaning}
# Load the economic dataset
economic_data <- read.csv("/Users/jonathanbernard/Desktop/UIUC/Spring 2024/GGIS 224/GGIS224/Final Project/Datasets/Chicago Health Atlas Data Download - Census Tracts.csv")

# Load the census tract shapefile
census_tracts <- st_read("/Users/jonathanbernard/Desktop/UIUC/Spring 2024/GGIS 224/GGIS224/Final Project/Datasets/Boundaries - Census Tracts - 2010.geojson")

# Remove rows with missing coordinates
economic_data <- economic_data %>%
  filter(!is.na(Longitude) & !is.na(Latitude))

# Convert the economic data to an sf object
economic_data_sf <- st_as_sf(economic_data, coords = c("Longitude", "Latitude"), crs = 4326)

# Merge the census tract shapefile with the economic data
census_tracts_economic <- st_join(census_tracts, economic_data_sf, join = st_intersects, left = TRUE)
```

```{r maps}
# Create an interactive heatmap using tmap for Unemployment Rate
tmap_mode("view")
tm_shape(census_tracts_economic) +
  tm_polygons("UMP_2018.2022", title = "Unemployment Rate",
              palette = "YlOrRd", alpha = 0.7) +
  tm_view(set.zoom.limits = c(10, 14)) +
  tm_scale_bar() +
  tm_minimap() +
  tm_credits("Data Source: Chicago Health Atlas", position = c("LEFT", "BOTTOM"))

# Create an interactive heatmap using tmap for Median Household Income
tmap_mode("view")
tm_shape(census_tracts_economic) +
  tm_polygons("INC_2018.2022", title = "Median Household Income",
              palette = "YlOrRd", alpha = 0.7) +
  tm_view(set.zoom.limits = c(10, 14)) +
  tm_scale_bar() +
  tm_minimap() +
  tm_credits("Data Source: Chicago Health Atlas", position = c("LEFT", "BOTTOM"))

# Create an interactive heatmap using tmap for Per Capita Income
tmap_mode("view")
tm_shape(census_tracts_economic) +
  tm_polygons("PCI_2018.2022", title = "Per Capita Income",
              palette = "YlOrRd", alpha = 0.7) +
  tm_view(set.zoom.limits = c(10, 14)) +
  tm_scale_bar() +
  tm_minimap() +
  tm_credits("Data Source: Chicago Health Atlas", position = c("LEFT", "BOTTOM"))

# Create an interactive heatmap using tmap for Poverty Rate
tmap_mode("view")
tm_shape(census_tracts_economic) +
  tm_polygons("POV_2018.2022", title = "Poverty Rate",
              palette = "YlOrRd", alpha = 0.7) +
  tm_view(set.zoom.limits = c(10, 14)) +
  tm_scale_bar() +
  tm_minimap() +
  tm_credits("Data Source: Chicago Health Atlas", position = c("LEFT", "BOTTOM"))

```

## Correlation Analysis
``` {r corr}
# Merge the aggregated crime data with the economic data using a spatial join
census_tracts_merged <- st_join(census_tracts_economic, census_tracts_crime, join = st_intersects, left = TRUE)

# Convert the sf object to a data frame
census_tracts_merged_df <- as.data.frame(census_tracts_merged)

# Select the relevant columns and rename them
correlation_data <- census_tracts_merged_df[, c("CRIME_COUNT", "UMP_2018.2022", "INC_2018.2022", "PCI_2018.2022", "POV_2018.2022")]
colnames(correlation_data) <- c("Crime Count", "Unemployment Rate", "Median Household Income", "Per Capita Income", "Poverty Rate")

# Convert the columns to numeric
correlation_data[] <- lapply(correlation_data, as.numeric)

# Calculate the correlation coefficients
correlation_results <- cor(correlation_data, use = "pairwise.complete.obs")

# Print the correlation matrix
print(correlation_results)
```

``` {r autocorr}
# Convert the sf object to a SpatialPolygonsDataFrame
census_tracts_sp <- as(census_tracts_merged, "Spatial")

# Create a spatial weights matrix based on queen contiguity
weights_nb <- poly2nb(census_tracts_sp, queen = TRUE)

# Convert the weights to a listw object
weights <- nb2listw(weights_nb, style = "W")

# Ensure the crime count variable is numeric
census_tracts_sp$CRIME_COUNT <- as.numeric(census_tracts_sp$CRIME_COUNT)

# Calculate Local Moran's I
local_moran <- localmoran(census_tracts_sp$CRIME_COUNT, weights)
# Check the column names of the local_moran object
colnames(local_moran)

# Add the Local Moran's I results to the census tract data
census_tracts_sp$local_moran_I <- local_moran[, "Ii"]
census_tracts_sp$local_moran_p <- local_moran[, "Pr(z != E(Ii))"]

# Convert the SpatialPolygonsDataFrame back to an sf object
census_tracts_lisa <- st_as_sf(census_tracts_sp)

# Create a custom palette for the LISA map
lisa_palette <- c("Not Significant" = "gray",
                  "High-High" = "red",
                  "Low-Low" = "blue",
                  "Low-High" = "lightblue",
                  "High-Low" = "pink")

# Create the LISA map
tmap_mode("plot")
tm_shape(census_tracts_lisa) +
  tm_polygons("local_moran_I", title = "Local Moran's I",
              style = "pretty", palette = lisa_palette,
              breaks = c(-Inf, -1.96, 1.96, Inf),
              labels = c("Low-Low", "Not Significant", "High-High"),
              border.col = "gray", border.alpha = 0.5) +
  tm_layout(legend.outside = TRUE)
```


``` {r global moran}
# Spatial Autocorrelation (Global Moran's I)
# Convert the sf object to a SpatialPolygonsDataFrame
census_tracts_sp <- as(census_tracts_merged, "Spatial")

# Create a spatial weights matrix based on queen contiguity
weights_nb <- poly2nb(census_tracts_sp, queen = TRUE)

# Convert the weights to a listw object
weights <- nb2listw(weights_nb, style = "W")

# Ensure the crime count variable is numeric
census_tracts_sp$CRIME_COUNT <- as.numeric(census_tracts_sp$CRIME_COUNT)

# Calculate Global Moran's I
global_moran <- moran.test(census_tracts_sp$CRIME_COUNT, weights)
print(global_moran)
```

``` {r eda}
# Regression Analysis
regression_model <- lm(CRIME_COUNT ~ Unemployment.Rate + Median.Household.Income + Per.Capita.Income + Poverty.Rate, data = correlation_data)
summary(regression_model)
```